\documentclass[12pt, oneside]{book}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}

\usepackage[utf8]{inputenc}
\usepackage[T2A,T1]{fontenc}
\usepackage{ragged2e}

\usepackage{setspace}
\onehalfspacing
\setlength{\parindent}{1.25cm}
\everymath{\displaystyle}
\usepackage{tocloft}
\cftsetindents{section}{1em}{2em}
\renewcommand\cfttoctitlefont{\hfill\Large\bfseries}
\renewcommand\cftaftertoctitle{\hfill\mbox{}}
\setlength{\cftbeforesecskip}{0.1cm}
\setlength{\cftbeforesubsecskip}{0.1cm}
\setlength{\cftbeforetoctitleskip}{0cm}
\setlength{\cftaftertoctitleskip}{0.4cm}
\setcounter{tocdepth}{2}

\usepackage[english,russian]{babel}
\usepackage[a4paper, left=3cm, top=2cm, right=1.5cm, bottom=2cm]{geometry}

\def\letus{%
  \mathord{\setbox0=\hbox{$\exists$}%
    \hbox{\kern 0.125\wd0%
      \vbox to \ht0{%
        \hrule width 0.75\wd0%
        \vfill%
      \hrule width 0.75\wd0}%
      \vrule height \ht0%
    \kern 0.125\wd0}%
  }%
}

\makeatletter
\renewcommand{\@makeschapterhead}[1]{%
  \vspace*{0\p@}
  {\parindent \z@ \center
    \normalfont
    \LARGE \bfseries #1\par\nobreak
    \addcontentsline{toc}{chapter}{#1}
    \vskip 10\p@
}}
\makeatother

\makeatletter
\renewcommand{\chapter}{%
  \if@openright\cleardoublepage\else\clearpage\fi
  \thispagestyle{plain}
  \global\@topnum\z@
  \@afterindentfalse
\secdef\@chapter\@schapter}

\renewcommand{\@makechapterhead}[1]{%
  \vspace*{0\p@}
  {\parindent \z@ \raggedright
    \normalfont
    \LARGE \bfseries \thechapter\quad #1\par\nobreak
    \vskip 20\p@
}}
\makeatother

\makeatletter
\newcommand{\custompagestyle}{%
  \begingroup
  \renewcommand{\ps@plain}{%
    \renewcommand{\@oddfoot}{\hfil\thepage\hfil}
    \renewcommand{\@evenfoot}{\hfil\thepage\hfil}
    \renewcommand{\@oddhead}{}
    \renewcommand{\@evenhead}{}
  }%
  \pagestyle{plain}
}
\makeatother

\newenvironment{customquote}
{\list{}{\leftmargin=0pt
    \rightmargin=0pt
    \topsep=0pt
    \partopsep=0pt
    \parsep=2pt
    \itemsep=0pt
  }%
  \normalfont\relax
\item\relax}
{\endlist}

\begin{document}
\thispagestyle{empty}
\begin{center}
  \textbf{\large САНКТ-ПЕТЕРБУРГСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ} \\[2cm]

  \text{\large ОТЧЕТ О НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ} \\[2cm]

  \text{\Large Шаго Павел Евгеньевич} \\[0.3cm]

  \text{22.Б07-ПУ, 01.03.02 Прикладная математика и информатика} \\[1cm]

  \textbf{\Large Планировщики 3} \\[3cm]

  \text{\large Научный руководитель} \\[0.3cm]
  \large{к.ф.-м.н., доцент Корхов В. В.} \\[10cm]
  \text{Санкт-Петербург}\\ \today

\end{center}

\newpage
\custompagestyle
\setcounter{page}{2}
\renewcommand{\contentsname}{Содержание}
\tableofcontents

\newpage
\chapter*{Введение}
\begin{quote}

  \quad Данная работа продолжает исследования [1] и [2], связанные с
  планировщиками процессов в операционных системах.

  В [2] были рассмотрены конкретные реализации в ядре Linux,
  такие как Completely Fair Scheduler (CFS) и Earliest Eligible Virtual Deadline
  First\\ (EEVDF), также был кратко описан фреймворк sched\_ext.

  \quad Несмотря на то, что алгоритм EEVDF считается высокопроизводительным и
  эффективным решением предыдущие работы продемонстрировали, что обобщенный
  подход не всегда является хорошим решением.

  \quad Настоящее исследование расширяет экспертизу в работе фреймворка\\
  sched\_ext. Реализован алгоритм EEVDF с помощью sched\_ext, проведено
  сравнение с эталонной реализацией в ядре Linux. Поставлена задача улучшения
  алгоритма планирования при условии что исполнение задач производится на
  процессоре с гетерогенной архитектурой (Intel Hybrid CPU, ARM big.LITTLE).

  \quad Фреймворк sched\_ext построен так, что позволяет практически
  без косвенных затрат загружать
  и выгружать новые алгоритмы во время исполнения (работы) системы,
  то поиск и реализация
  повышающих эффективность использования ресурсов процессора
  алгоритмов планирования
  представляется очень перспективным.

  \quad Современные процессорные архитектуры все чаще проектируются
  на основе гетерогенного принципа,
  при котором в рамках одного кристалла объединяются вычислительные
  ядра, различающиеся по уровню производительности,
  энергопотреблению и микроархитектурным особенностям. Такой подход
  позволяет более гибко распределять вычислительные
  нагрузки между ядрами, оптимизируя использование ресурсов в
  зависимости от характера выполняемых задач.

  \quad Высокопроизводительные ядра ориентированы на обработку
  ресурсоемких и чувствительных к задержкам вычислений,
  тогда как энергоэффективные ядра предназначены для фоновых,
  периодических или менее требовательных операций.

  \quad Разработка эффективных планировщиков для гетерогенных
  архитектур остается актуальной
  задачей в системном программировании, поскольку напрямую влияет на
  производительность, энергопотребление
  и отзывчивость систем. Улучшения в этой области позволяют
  оптимизировать использование ресурсов
  в современных вычислительных платформах.
\end{quote}

\chapter{Фреймворк sched\_ext}
\section{Введение}
\begin{quote}
  Инфраструктура \bf sched\_ext \normalfont предоставляет возможности
  для разработки и исполнения планировщиков процессов на базе набора
  eBPF программ исполняемых в
  виртуальной машине ядра Linux.

  sched\_ext позволет динамически подключать альтернативные алгоритмы
  планирования без
  необходимости модификации и перекомпиляции ядра.

  Более того, даже перезагружать систему нет необходимости, поскольку
  для загрузки
  нового алгоритма sched\_ext просто делает системный вызов bpf(),
  далее как и любая eBPF программа
  алгоритм планирования пройдет верификацию, JIT компиляцию и сразу начнет
  работу в виртуальной машине.

  Инфраструктура sched\_ext встроена в существующую подсистему
  планирования Linux и использует
  стандартные структуры задач (struct task) и очереди runqueue.

  При активации sched\_ext управление выбором следующей задачи происходит из
  общей (для ядер процессора) очереди dsq (dispatch queue) задачи в которую
  помещает алгоритм планирования. При этом предоставляется
  возможность модификации
  алгоритма перехода задач из общей очереди в локальные dsq (локальные очереди
  исполнения dsq -- очереди задач для каждого отдельного ядра процессора).
\end{quote}

\section{Целостность}
\begin{quote}
  Ядро Linux сохраняет контроль над важными аспектами выполнения, включая:
  \begin{itemize}
    \item переключение контекста
    \item управление состояниями задач
    \item обработку прерываний и таймеров
    \item обеспечение изоляции
  \end{itemize}

  Благодаря этому sched\_ext реализует модель управляемого расширения, в которой
  пользовательский (динамически подгружаемый) код не может напрямую
  нарушить целостность ядра.
\end{quote}

\section{Архитектура}
\begin{quote}
  На sched\_ext распостраняются архитектурные особенности eBPF,\\
  (sched\_ext реализован через eBPF, sched\_ext планировщик является eBPF
  программой).

  eBPF байт-код (скомпилированная eBPF программа) всегда проходит верификацию
  перед тем как он будет отправлен в виртуальную машину или в JIT компилятор
  (предоставляется возможность не использовать JIT компилятор вовсе,
    скомпилированный байт-код после верификации сразу будет исполняться в
  виртуальной машине).

  Верификация предполагает такие шаги как:
  \begin{itemize}
    \item проверка на завершимость

      (проверяется что во всех возможных путях
        графа потока управления (CFG, control flow graph) программа
        завершается и не останется в\\ неопределенном состоянии,
      бесконечном цикле)

    \item запрет небезопасных операций с памятью

      (доступ к динамической памяти предоставляется
        через вспомогательные функции которые работают с памятью
        владение которой
      заранее определены за этой eBPF программой (механизм eBPF Maps)).
  \end{itemize}

  Эти свойства обеспечивают предсказуемость и стабильность работы реализованного
  через sched\_ext планировщика, при этом даже если какие-то ошибки с
  eBPF программой
  все таки будут обнаружены во время исполнения произойдет откат
  (fallback) на стандартный
  планировщик EEVDF.

  Основные функции программного интерфейса sched\_ext:
  \begin{itemize}
    \item select\_cpu() -- выбор потока исполнения (физического или
      логического ядра) процессора
    \item enqueue() -- вставка задачи в глобальную очередь dsq
    \item dispatch() -- перемещение задачи в локальную dsq
  \end{itemize}

  Очистка очередей (постановка задач на исполнение из очередей) происходит
  автоматически. Каждый тик системного таймера $ 1/HZ $ проверяется возможность
  исполнять задачу дальше ($ HZ $ -- частота системного таймера).
  Исполняемая задача
  может быть приостановлена прерыванием сколь угодно раз.

  Задача снимается с выполнения из-за обнуления ее scx\_slice, это происходит
  автоматически когда заканчивается выделенная задаче квота, также есть
  возможность в алгоритме планирования обнулить (специальным прерыванием) задаче
  scx\_slice (таким образом получаем вытеснение планировщиком).

  Как только переменная scx\_slice обнулена ядро считается доступным
  и происходит выбор
  следующей задачи из dsq.
\end{quote}

\chapter{Обзор литературы}
Данная глава представляет собой обзор новых довольно интересных статей
опубликованных со времени написания [2].

\section{Linux Kernel Scheduler Evaluation for Performance-Critical Telecom
Workloads}
\begin{quote}
  В работе рассматривается широкое внедрение облачных технологий
  в телекоммуникационном секторе (telco), что требует систем,
  способных обеспечивать низкие задержки.
  Основной проблемой, с которой сталкивается Ericsson в облачных
  средах на базе Kubernetes, является возникновение
  высоких задержек, когда загрузка процессора превышает 50\%. Это делает оценку
  производительности планировщика LAVD в диапазоне нагрузок от 50\% до 95\%
  необходимой практически (на практике) задачей, чтобы обеспечить
  функционирование
  telco-приложений в соответствии с их назначением.

  Центральной целью диссертации является оценка эффективности планировщика
  Latency-criticality Aware Virtual Deadline (LAVD) при обработке критичных к
  производительности телекоммуникационных рабочих нагрузок. LAVD,
  первоначально разработанный
  для игровых рабочих нагрузок, которые имеют сходство
  с telco-нагрузками по требованиям к задержке и ресурсам, представляет собой
  перспективную попытку решения проблем с задержками. Планировщик
  LAVD был реализован с использованием
  новой инфраструктуры sched\_ext в ядре Linux.

  Для проведения оценки был разработан специальный симулятор. Этот
  настраиваемый, многопоточный симулятор,
  написанный на C++, генерирует синтетические рабочие нагрузки,
  имитирующие характеристики трафика telco-систем,
  основанные на статистическом анализе данных трассировки Ericsson.
  Для моделирования времени выполнения (burst times)
  реальных рабочих нагрузок трафика использовался статистический
  анализ, который показал, что распределение лучше всего
  описывается бета-распределением, что дало наибольшее значение p-value (0.084)
  при проверке критерием\\ Колмогорова-Смирнова. Симулятор также
  поддерживает генерацию фоновых интерферирующих
  рабочих нагрузок, которые конкурируют за время ЦП, позволяя
  моделировать реалистичные сценарии конфликта.

  В ходе исследования сравнивались три планировщика: LAVD,
  scx\_simple (еще один планировщик sched\_ext)
  и EEVDF, который является стандартным планировщиком ядра
  Linux и служил базовой единицей для сравнения (baseline) производительности.
  EEVDF подробно описан в [2]. LAVD, как планировщик, ориентированный
  на критичность
  задержки, использует сложную модель, основанную на времени выполнения, частоте
  пробуждения и частоте ожидания, чтобы назначать более ранние виртуальные
  дедлайны (Virtual Deadlines) более критичным задачам. В отличие от них,
  scx\_simple -- это минималистичный планировщик, который по
  умолчанию использует взвешенное виртуальное время,
  но не поддерживает перехват (preemption), что отличает его от EEVDF и LAVD.

  Результаты показали, что LAVD имеет потенциал для значительного
  сокращения среднего времени
  оборота (mean turnaround time), особенно в сценариях с высокой
  загрузкой процессора и наличием интерферирующих
  рабочих нагрузок. В среде Kubernetes Minikube LAVD
  продемонстрировал улучшение среднего времени оборота по сравнению
  с EEVDF в диапазоне от 6\% до 81\%, а улучшение 99-го процентиля (tail
  latency) достигало 90\%. Однако, scx\_simple показал удивительно
  хорошие результаты, превзойдя LAVD,
  когда количество интерферирующих рабочих нагрузок было низким.
  Например, в условиях, типичных для Ericsson
  (50\% загрузки ЦП трафиком и 10\% интерферирующей нагрузкой),
  scx\_simple постоянно превосходил LAVD.

  Ключевой вывод исследования состоит в том, что превосходство не принадлежит
  какому-то одному конкретному планировщику, а скорее демонстрируется
  потенциалом
  всей инфраструктуры sched\_ext. Эта гибкость, позволяющая быстро
  проводить эксперименты и оптимизировать код,
  делает ее перспективным инструментом для адаптации планирования ЦП
  к требованиям, специфичным для домена telco.
  Кроме того, попытки оптимизировать параметры LAVD, такие, как
  минимальный и максимальный временной срез, не привели к
  значительным улучшениям по сравнению с настройками по умолчанию,
  что позволяет предположить, что LAVD уже хорошо
  оптимизирован для широкого спектра сценариев.

  Среди направлений для будущей работы предлагается улучшение
  симулятора за счет использования более широкого
  и разнообразного набора трасс или непосредственного использования
  трасс для управления выполнением вместо статистических
  распределений. Также рекомендуется расширить анализ, включив
  дополнительные метрики, такие, как время ожидания
  и количество переключений контекста, а также провести оценку
  планировщиков в распределенном кластере Kubernetes,
  чтобы выявить потенциальные узкие места, которые могут не
  проявляться в локальной среде Minikube.
\end{quote}

\section{Rethinking Provenance Completeness with
a Learning-Based Linux Scheduler}
\begin{quote}
  Проблема обеспечения полноты данных о происхождении (provenance)
  критически важна для аудита действий системы,
  что необходимо для анализа первопричин угроз безопасности и их
  последствий. Системы сбора данных о происхождении должны
  функционировать как эталонный монитор (reference monitor),
  гарантируя полный захват всех системных событий, чтобы
  ведение журнала нельзя было обойти. Однако, современные системы
  сбора данных сталкиваются с серьезной проблемой,
  известной как "угроза суперпродюсера" (super producer threat), при
  которой чрезмерная генерация событий может перегрузить
  систему, вынуждая ее отбрасывать критически важные для безопасности
  записи, что позволяет злоумышленнику скрыть свои
  действия. Эта угроза представляет значительный вызов гарантиям
  безопасности эталонного монитора.

  Существующие решения и подходы сталкиваются с серьезными
  ограничениями при противодействии угрозе суперпродюсера. Традиционные
  планировщики Linux, такие, как CFS и EEVDF, разработаны для
  достижения общих целей производительности, таких как
  пропускная способность, справедливость и задержка, но им не хватает
  понимания уникальных требований полноты данных
  о происхождении. Эта нехватка приводит к потере данных, что
  компрометирует надежность и безопасность системы.
  Некоторые современные защитные механизмы, например NoDrop,
  предлагают изоляцию ресурсов, но их внедрение затруднительно,
  поскольку требует специализированной аппаратной поддержки
  (например, Intel Memory Protection Keys), тесно связано с
  устаревшими ядрами и может вызывать ошибки, связанные с атомарными
  операциями, потенциально приводящие
  к сбоям ядра (kernel panics).

  В качестве инновационного решения этих проблем представлена система
  Aegis -- самообучающийся планировщик для
  ядра Linux, специально разработанный для обеспечения полноты данных
  о происхождении. Основная идея заключается в том,
  что планировщик ядра может решить проблему несвоевременного
  потребления генерируемых событий, которое приводит к переполнению
  буфера и потере данных, путем выделения достаточных ресурсов
  системе происхождения. Aegis преследует три основные
  цели: полнота (захват всех событий даже при экстремальных
  нагрузках), эффективность (поддержание или улучшение производительности
  системы) и справедливость (сбалансированное распределение ресурсов
  для предотвращения старвации задач).

  Архитектура Aegis основана на двухслойном подходе, где первый слой
  создает основу планирования, а второй слой
  настраивает ее с помощью обучения для оптимизации
  производительности и смягчения атак. Планировщик использует основанную
  на очередях (queue-based) структуру, где задачи делятся на основную
  и несколько непервичных очередей. Непервичные очереди,
  предназначенные для задач, связанных с происхождением, имеют
  заданное время ожидания, которое выступает в качестве естественного
  бюджета ресурсов. Очередь становится доступной для обработки только
  тогда, когда время, прошедшее с момента последнего
  выполнения задачи в ней, превышает установленное время ожидания,
  что обеспечивает строгую политику выделения ресурсов
  и предотвращает перегрузку. Aegis также обеспечивает
  справедливость, потребляя непервичные очереди с наибольшим
  показателем (весом) старвации (те, которые ждали дольше всего), гарантируя
  пропорциональное распределение ресурсов и предотвращая старвацию
  задач.

  Ключевым элементом Aegis является использование обучения с
  подкреплением (Reinforcement Learning, RL),
  реализуемого с помощью легковесной DeepQ-Network (DQN). DQN
  прогнозирует оптимальные решения о планировании, основываясь
  на контексте задачи, который включает как поведенческие
  характеристики задачи, так и признаки состояния системы
  происхождения (например, скорость генерации событий, доступность буфера).

  Процесс обучения управляется двойным механизмом вознаграждения:
  вознаграждение за происхождение ($r_c$) наказывает за потерю событий
  для обеспечения полноты, а вознаграждение за утилизацию ($r_p$)
  минимизирует простой процессора для повышения общей эффективности.
  Aegis реализован в пространстве ядра Linux с использованием подсистемы
  eBPF и фреймворка sched\_ext.

  В результате оценки Aegis с использованием различных
  макробенчмарков и двух систем происхождения (Sysdig и eAudit)
  была подтверждена его эффективность. Aegis последовательно
  демонстрировал нулевую потерю событий во всех тестовых сценариях,
  даже в условиях высоких нагрузок, где другие планировщики, такие как
  EEVDF, LAVD и Rusty, теряли от 39\% до более 98\% событий. Более
  того, Aegis не только предотвращает потерю событий,
  но и обеспечивает высокую производительность, в среднем улучшая
  время выполнения по сравнению с EEVDF, LAVD и Rusty.
  Общие вычислительные затраты, связанные с планированием,
  остаются низкими: в типичных сценариях
  они составляют менее 0.5\%, а в самых требовательных -- около
  2.44\%, благодаря использованию дельта-функции для пропуска
  ненужных решений планирования.

  Таким образом, Aegis обеспечивает выполнение гарантий безопасности
  эталонного монитора для систем сбора данных
  о происхождении, эффективно предотвращая угрозу суперпродюсера
  путем интеграции обучения с подкреплением в планировщик ядра.
  Aegis доказывает, что адаптивный, управляемый данными подход
  является мощным и производительным способом устранения
  критических проблем, с которыми не справляются традиционные и
  аппаратные механизмы защиты.
\end{quote}

\section[Mixture-of-Schedulers]{Mixture-of-Schedulers: An Adaptive Scheduling
Agent as a Learned Router for Expert Policies}
\begin{quote}
  Современные планировщики операционных систем сталкиваются с
  серьезной проблемой: единая, статичная политика
  не может обеспечить оптимальную производительность в условиях
  разнообразия и динамичности нагрузок, характерных
  для современных систем. Рост числа гетерогенного оборудования
  (Intel Hybrid CPU) и разнообразных архитектур
  приложений (микросервисы, интерактивные задачи, пакетная обработка)
  обострил фундаментальные компромиссы между
  справедливостью, пропускной способностью и задержкой. В ответ на
  эту проблему, статья предлагает новую парадигму:
  динамический выбор оптимальной политики из портфеля
  специализированных планировщиков вместо проектирования единого,
  монолитного решения.

  Эта философия реализована в виде адаптивного агента планирования\\
  (Adaptive Scheduling Agent, ASA),
  который представляет собой легковесную структуру, выступающую в
  роли интеллектуального маршрутизатора для специализированных
  политик планирования. ASA разработан на основе инфраструктуры
  sched\_ext.

  Архитектура ASA декомпозирует сложную задачу планирования
  на две более простые подзадачи
  \begin{itemize}
    \item распознавание шаблона рабочей нагрузки
    \item сопоставление политики
  \end{itemize}
  Это позволяет ASA во время выполнения выбирать наиболее подходящую политику
  из набора доступных экспертов.

  В основе интеллекта ASA лежит цикл восприятия, решения и действия.
  Модуль восприятия (Perception module) непрерывно
  отслеживает метрики времени выполнения, такие как использование
  процессора, активность ввода/вывода и сетевой трафик, собирая данные
  из различных источников, включая eBPF интерфейсы и файловую систему
  procfs. Модуль решения (Decision module) использует обученную
  модель машинного обучения (классификатор на основе ансамбля,
  преимущественно XGBoost) для распознавания текущего шаблона нагрузки.
  Для обеспечения стабильности решений в динамической среде
  применяется алгоритм взвешенного по времени вероятностного голосования
  (Time-Weighted Probability Voting), который использует механизм
  голосования с экспоненциальным затуханием для фильтрации
  кратковременного системного шума. Модуль действия (Action module)
  затем выполняет динамическое переключение на
  выбранный оптимальный планировщик через фреймворк sched\_ext.

  Развертывание ASA включает комплексный трехэтапный автономный
  процесс подготовки (Offline Prepare Pipeline),
  который создает агента планирования. Он
  начинается с прототипного обучения (Prototype Learning)
  для создания базовой модели распознавания и первичного
  сопоставления планировщиков, за которым следует динамическая калибровка
  косвенных затрат (Dynamic Overhead Calibration), имитирующая
  стоимость переключения планировщиков. Завершающий этап: обучение
  модели обобщения\\ (Generalization Model Training), позволяет ASA
  уточнить свои модели в реальной среде.

  Для оценки эффективности авторы
  разработали критерий оценки, ориентированный на пользовательский
  опыт (User Experience Oriented Evaluation Criteria), который измеряет
  производительность на основе метрик, напрямую влияющих на
  восприятие пользователя (например, задержка взаимодействия с
  пользовательскими интерфейсами, их плавность),
  смещая цель оптимизации от системной эффективности к оптимизации
  пользовательского опыта. Этот критерий отражает сложную природу
  человеческого восприятия, выделяя зону наилучшего восприятия
  ("Sweet Spot Region").

  Комплексная оценка подтвердила, что парадигма динамического выбора
  ASA превосходит статическую оптимизацию.
  ASA стабильно превосходит EEVDF, показывая
  лучшие результаты в 86.4\% тестовых сценариев. Выбранные ASA
  политики являются близкими к оптимальным, входя в тройку
  лучших планировщиков в 78.9\% всех сценариев.

  Агент также продемонстрировал сильную способность к обобщению,
  поддерживая или даже улучшая производительность
  на новых, ранее неизвестных аппаратных платформах (пример:
  обучение на архитектуре x86\_64, эксплуатация на arm).

  Практичность ASA подтверждается довольно низкими косвенными затратами
  для масштаба системы: агент потребляет в среднем всего 1.45\% одного
  ядра процессора и 297 магабайт памяти.
  Хотя потолок производительности ASA определяется качеством
  и разнообразием портфеля экспертных планировщиков, это также
  является преимуществом, поскольку позволяет масштабировать
  улучшения путем интеграции новых, более продвинутых планировщиков,
  разработанных сообществом. В целом, ASA предлагает жизнеспособный
  технический путь для создания следующего
  поколения интеллектуальных, адаптивных планировщиков операционных систем.
\end{quote}

\chapter{Реализация алгоритма EEVDF через фреймворк sched\_ext}
\section{Задачи}
\begin{quote}
  \begin{itemize}
    \item Исследовать диссертацию про алгоритм EEVDF [7]
    \item Реализовать в соответствии с алгоритмом планировщик
      используя sched\_ext
      %\item Провести сравнение задержки между алгоритмами
  \end{itemize}
\end{quote}

\section{Мотивация}
\begin{quote}
  Выбор данной задачи обусловлен несколькими факторами и открывает
  важные направления для дальнейших исследований.

  Реализация планировщика EEVDF в рамках инфраструктуры sched\_ext
  создает возможность
  провести количественную оценку косвенных затрат,
  возникающих при использовании данной конфигурации, что необходимо
  для абсолютной
  оценки эффективности получившегося практического решения.

  Кроме того, разработанная реализация служит воспроизводимой основой
  для будущего
  прямого сравнения альтернативной реализации планировщика (специально
  разработанного для гетерогенного процессора) и позволяет выявлять
  практические ограничения.

  Наконец, работа приносит автору существенный практический опыт
  разработки и интеграции
  планировщиков в системное окружение, что важно для последующих
  экспериментальных и прикладных исследований.
\end{quote}

\section{Краткое погружение в реализацию}
\begin{quote}
  В основе алгоритма EEVDF лежит присвоение каждой задаче
  виртуального допустимого времени
  (VE) и виртуального крайнего срока (VD), вычисляемых следующим образом:

  VE = max(VE\_previous, V\_now - slice), где V\_now -- глобальное
  виртуальное время, а slice -- временная квота задачи
  (упомянутый ранее scx\_slice).

  VD = VE + (slice / weight), масштабируется таким образом, чтобы
    задачи с более высоким весом (более высоким приоритетом) получали
    более короткие эффективные сроки.

    Задачи распределяются на основе самого раннего VD, что способствует
    справедливости: более ресурсоемкие задачи потребляют больше
    виртуального времени, но соответственно наказываются. Это
    предотвращает бесконечную задержку задач с низким приоритетом, что
    является распространенной проблемой в других алгоритмах
    справедливого распределения.

    В моей реализации я поддерживаю глобальный контекст (eevdf\_ctx),
    отслеживающий vtime\_now (текущее виртуальное время) и total\_weight (сумма
    весов всех задач). Общая очередь диспетчеризации dsq хранит задачи,
    упорядоченные по их виртуальному времени VD, используя встроенную
    в sched\_ext функцию вставки с упорядочением по виртуальному времени
    (scx\_bpf\_dsq\_insert\_vtime()).
  \end{quote}

  \section{Подробности реализации}
  \begin{quote}
    Изначально определяется карта eBPF (eBPF Maps) для глобальных
    данных (global\_data) для хранения контекста EEVDF.
    Также определяется карта статистики для каждого процессора,
    которая отслеживает метрики: количество незадействованных
    ядер и количество задач в очереди.

    Общая очередь dsq (id 0) создается во время инициализации
    (eevdf\_init).

    Выбор ядра процессора (eevdf\_select\_cpu):
    когда задача становится активной, используется выбор ядра по умолчанию из
    sched\_ext и проверяем наличие незадействованных ядер. Если обнаруживается
    свободное ядро, тогда увеличиваем статистику и добавляем задачу в
    локальную очередь задач (dsq) с использованием
    среза (scx\_slice) по умолчанию -- оптимизируя выполнение для немедленного
    запуска и уменьшая косвенные затраты на миграцию.

    Постановка задач в очередь (eevdf\_enqueue):
    считывается глобальный контекст, ограничиваем
    виртуальное допустимое время VE задачи, вычисляем виртуальный крайний
    срок VD как VE + (slice * SCALE / weight).
    Задача добавляется в общую очередь задач dsq с использованием
    упорядочивания по виртуальному времени (scx\_bpf\_dsq\_insert\_vtime),
    обеспечивая порядок сначала самый ранний крайний срок.
    Коэффициент SCALE (100) позволяет вычислять дробные коэффициенты
    через целочисленную арифметику.

    Диспетчеризация задач (eevdf\_dispatch): задачи перемещаются из общей
    очереди dsq в локальную очередь на текущем ядре, позволяя ядру
    выбирать следующую готовую к выполнению задачу на основе
    предварительно упорядоченного виртуального времени VD.

    Начало выполнения (eevdf\_running): продвигаем глобальное
    виртуальное время, если виртуальное время задачи превышает его.

    \newpage
    Остановка (eevdf\_stopping): обновление виртуального времени задачи
    путем добавления использованного задачей времени, масштабированного
    по весу, с учетом фактического времени выполнения.

    Включение/отключение (eevdf\_enable/eevdf\_disable):
    корректировка веса\\ total\_weight при входе или выходе
    задач из планировщика. Обеспечивает поддержку глобального состояния.

    Изменение веса (eevdf\_set\_weight): динамическая корректировка
    виртуального времени для сохранения задержки (разницы между
    глобальным виртуальным временем и виртуальным временем задачи) при
    изменениях веса. Это свойство обеспечивает пропорциональное масштабирование
    для избежания несправедливых скачков приоритета.

    Код избегает сложных структур данных, полагаясь на примитивы dsq из
    sched\_ext для повышения эффективности. Обработка ошибок
    минимальна, с ранним возвратом при сбоях поиска в карте, что
    обеспечивает базовую надежность.
  \end{quote}

  \section{Итоги}
  \begin{quote}
    В результате разработан планировщик, обеспечивающий справедливое
    распределение процессорного времени пропорционально весам задач
    и гарантирующий низкую задержку для интерактивных рабочих нагрузок.
    Анализ статистических счётчиков показывает эффективное использование
    процессора как в режиме ожидания, так и при интенсивной нагрузке.

    Хотя этот прототип хорошо отражает суть EEVDF, существует множество
    возможностей для его усовершенствования. Например, можно выбирать
    виртуальное
    время для каждого ядра с учетом его архитектуры (реализовать поддержку
    гетерогенности для планирования) или настраивать планировщик под конкретные
    задачи. Гибкость sched\_ext позволяет довольно просто реализовывать в
    дальнейшем эти расширения.

    Также на текущий момент тестирование эффективности в моей конфигурации
    ограничивается общими тестами производительности GeekBench, Passmark и
    выводом локальных метрик всех ядер (из карт eBPF).

    Полный код и инструкции по развертыванию можно получить в репозитории
    [8].
  \end{quote}

  \newpage
  \section{Направления дальнейшей работы}
  \begin{quote}
    Остается довольно много задач для достижения конечных целей,
    включая:
    \begin{itemize}
      \item разработку тестового пакета для оценки эффективности
      \item определение переменных, параметров и ограничений
      \item построение специализированной математической модели
      \item создание алгоритма на базе модели
      \item реализация полученного алгоритма
    \end{itemize}
  \end{quote}

  %\chapter{Матмодель задачи}

  \chapter*{Заключение}
  \begin{quote}
    \quad В данной работе получены основополагающие для дальнейшей работы
    результаты. Успешно реализован алгоритм планирования EEVDF с использованием
    инфраструктуры sched\_ext, углублена и обновлена научная
    экспертиза в аналогичных
    решениях которые появились за последние полгода.
    Продолжающееся развитие данной области показывает, что решаемые проблемы
    актуальны и востребованы.

    \quad В настоящей работе осознанно опущено развернутое обсуждение
    значимости разработки
    более эффективных алгоритмов планирования, где это допустимо ограничениями
    формата. Такое решение обусловлено рядом причин. Во-первых, с момента
    публикации работ [1] и [2] не произошло принципиальных изменений
    в оценке актуальности
    рассматриваемой темы, которая по-прежнему сохраняет высокую
    значимость, вследствие чего
    повторение ранее приведённых обоснований представляется
    избыточным. Во-вторых, данное
    исследование следует рассматривать как логическое продолжение предыдущих
    частей, в связи с чем акцент на значимости темы целесообразно
    сместить в заключение.

    \quad Выход на рынок большего количества процессоров с
    гетерогенной компоновкой делает
    решаемую проблему все более актуальной.
    Современные задачи, включая обеспечение предсказуемых задержек,
    адаптацию к разнородным
    рабочим нагрузкам и поддержку гетерогенной архитектуры
    современных вычислительных платформ,
    требуют применения всё более точных и адаптивных решений. В связи
    с этим исследования
    в данной области способствуют не только совершенствованию
    существующих реализаций,
    но и создают предпосылки для разработки новых, более
    универсальных и надёжных планировщиков.

    \quad Таким образом, проведённое исследование дополняет и
    расширяет результаты,
    представленные в работах [1] и [2]. Полученные выводы позволяют смело
    переходить от описательного и экспериментального уровня к формальному
    математическому моделированию планировщика и разработке алгоритмов,
    ориентированных на гетерогенные вычислительные системы с
    разнородными ресурсами и нагрузками.

    \quad В дальнейшей работе планируется реализация тестового пакета,
    предназначенного для воспроизводимого сбора и анализа метрик
    качества планирования.
    Наличие такого инструментария позволит валидировать
    разрабатываемые модели и алгоритмы,
    сопоставляя теоретические результаты с практическим поведением системы.
  \end{quote}

  \renewcommand{\bibname}{\large СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ}
  \begin{thebibliography}{9}
    \vspace*{0.3cm}
    \bibitem{1}
    Павел Е. Шаго Отчет о научно-исследовательской работе:
    Планировщики б. и. 2024
    \bibitem{2}
    Павел Е. Шаго Отчет о научно-исследовательской работе: Планировщики 2 б. и.
    2025
    \bibitem{3}
    Joseph Y-T. Leung\ Handbook of Scheduling: Algorithms, Models, and
    Performance Analysis CRC Press 2004
    \bibitem{4} Michelle Galin, Anna Hedblom Linux Kernel Scheduler Evaluation
    for Performance-Critical Telecom Workloads Linköping University 2025
    \bibitem{5} Jinsong Mao, Benjamin E. Ujcich, Shiqing Ma
    Rethinking Provenance
    Completeness with a Learning-Based Linux Scheduler arXiv 2025
    \bibitem{6} Xinbo Wang, Shian Jia, Ziyang Huang, Jing Cao, Mingli Song
    Mixture-of-Schedulers: An Adaptive Scheduling Agent as a Learned Router for
    Expert Policies arXiv 2025
    \bibitem{7}
    Ion Stoica, Hussein Abdel-Wahab Earliest Eligible Virtual Deadline First
    : A Flexible and Accurate Mechanism for Proportional Share
    Resource Allocation
    Old Dominion University 1996
    \bibitem{8} A1349 Pavel Shago [Электронный ресурс].
    -- Режим доступа: \url{https://github.com/shgpavel/A1349} -- Дата обращения
    16.12.2025.
    \bibitem{9} Andrew S. Tanenbaum, Herbert Bos\ MODERN OPERATING
    SYSTEMS Pearson
    Education 2023
    \bibitem{10}
    Liz Rice Learning eBPF O’Reilly Media, Inc 2023
    \bibitem{11}
    Torvalds L. Linux Kernel [Электронный ресурс] / L. Torvalds.
    -- Режим доступа: \url{https://github.com/torvalds/linux} -- Дата обращения
    04.12.2025.
    \bibitem{12}
    sched-ext/scx [Электронный ресурс]. -- Режим доступа: \\
    \url{https://github.com/sched-ext/scx} -- Дата обращения 07.12.2025.
    \bibitem{13}
    lkml [Электронный ресурс]. -- Режим доступа: \url{https://lkml.org}
    -- Дата обращения 24.11.2025.
  \end{thebibliography}

  \end{document}
