\documentclass[12pt, oneside]{book}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}

\usepackage[utf8]{inputenc}
\usepackage[T2A,T1]{fontenc}
\usepackage{ragged2e}

\usepackage{setspace}
\onehalfspacing
\setlength{\parindent}{1.25cm}
\everymath{\displaystyle}
\usepackage{tocloft}
\cftsetindents{section}{1em}{2em}
\renewcommand\cfttoctitlefont{\hfill\Large\bfseries}
\renewcommand\cftaftertoctitle{\hfill\mbox{}}
\setlength{\cftbeforesecskip}{0.1cm}
\setlength{\cftbeforesubsecskip}{0.1cm}
\setlength{\cftbeforetoctitleskip}{0cm}
\setlength{\cftaftertoctitleskip}{0.4cm}
\setcounter{tocdepth}{2}

\usepackage[english,russian]{babel}
\usepackage[a4paper, left=3cm, top=2cm, right=1.5cm, bottom=2cm]{geometry}

\def\letus{%
  \mathord{\setbox0=\hbox{$\exists$}%
    \hbox{\kern 0.125\wd0%
      \vbox to \ht0{%
        \hrule width 0.75\wd0%
        \vfill%
      \hrule width 0.75\wd0}%
      \vrule height \ht0%
    \kern 0.125\wd0}%
  }%
}

\makeatletter
\renewcommand{\@makeschapterhead}[1]{%
  \vspace*{0\p@}
  {\parindent \z@ \center
    \normalfont
    \LARGE \bfseries #1\par\nobreak
    \addcontentsline{toc}{chapter}{#1}
    \vskip 10\p@
}}
\makeatother

\makeatletter
\renewcommand{\chapter}{%
  \if@openright\cleardoublepage\else\clearpage\fi
  \thispagestyle{plain}
  \global\@topnum\z@
  \@afterindentfalse
\secdef\@chapter\@schapter}

\renewcommand{\@makechapterhead}[1]{%
  \vspace*{0\p@}
  {\parindent \z@ \raggedright
    \normalfont
    \LARGE \bfseries \thechapter\quad #1\par\nobreak
    \vskip 20\p@
}}
\makeatother

\makeatletter
\newcommand{\custompagestyle}{%
  \begingroup
  \renewcommand{\ps@plain}{%
    \renewcommand{\@oddfoot}{\hfil\thepage\hfil}
    \renewcommand{\@evenfoot}{\hfil\thepage\hfil}
    \renewcommand{\@oddhead}{}
    \renewcommand{\@evenhead}{}
  }%
  \pagestyle{plain}
}
\makeatother

\newenvironment{customquote}
{\list{}{\leftmargin=0pt
    \rightmargin=0pt
    \topsep=0pt
    \partopsep=0pt
    \parsep=2pt
    \itemsep=0pt
  }%
  \normalfont\relax
\item\relax}
{\endlist}

\begin{document}
\thispagestyle{empty}
\begin{center}
  \textbf{\large САНКТ-ПЕТЕРБУРГСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ} \\[2cm]

  \text{\large ОТЧЕТ О НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ} \\[2cm]

  \text{\Large Шаго Павел Евгеньевич} \\[0.3cm]

  \text{22.Б07-ПУ, 01.03.02 Прикладная математика и информатика} \\[1cm]

  \textbf{\Large Планировщики 3} \\[3cm]

  \text{\large Научный руководитель} \\[0.3cm]
  \large{к.ф.-м.н., доцент Корхов В. В.} \\[10cm]
  \text{Санкт-Петербург}\\ \today

\end{center}

\newpage
\custompagestyle
\setcounter{page}{2}
\renewcommand{\contentsname}{Содержание}
\tableofcontents

\newpage
\chapter*{Введение}
\begin{quote}

  \quad Данная работа продолжает исследования [1] и [2], связанные с
  планировщиками процессов в операционных системах.

  В [2] были рассмотрены конкретные реализации в ядре Linux,
  такие как Completely Fair Scheduler (CFS) и Earliest Eligible Virtual Deadline
  First\\ (EEVDF), также был кратко описан фреймворк sched\_ext.

  \quad Несмотря на то, что алгоритм EEVDF считается высокопроизводительным и
  эффективным решением предыдущие работы продемонстрировали, что обобщенный
  подход не всегда является хорошим решением.

  \quad Настоящее исследование расширяет экспертизу в работе фреймворка\\
  sched\_ext. Реализован алгоритм EEVDF с помощью sched\_ext, проведено
  сравнение с эталонной реализацией в ядре Linux. Поставлена задача улучшения
  алгоритма планирования при условии что исполнение задач производится на
  процессоре с гетерогенной архитектурой (Intel Hybrid CPU, ARM big.LITTLE).

  \quad Фреймворк sched\_ext построен так, что позволяет практически
  без косвенных затрат загружать
  и выгружать новые алгоритмы во время исполнения (работы) системы,
  то поиск и реализация
  повышающих эффективность использования ресурсов процессора
  алгоритмов планирования
  представляется очень перспективным.

  \quad Современные процессорные архитектуры все чаще проектируются
  на основе гетерогенного принципа,
  при котором в рамках одного кристалла объединяются вычислительные
  ядра, различающиеся по уровню производительности,
  энергопотреблению и микроархитектурным особенностям. Такой подход
  позволяет более гибко распределять вычислительные
  нагрузки между ядрами, оптимизируя использование ресурсов в
  зависимости от характера выполняемых задач.

  \quad Высокопроизводительные ядра ориентированы на обработку
  ресурсоемких и чувствительных к задержкам вычислений,
  тогда как энергоэффективные ядра предназначены для фоновых,
  периодических или менее требовательных операций.

  \quad Разработка эффективных планировщиков для гетерогенных
  архитектур остается актуальной
  задачей в системном программировании, поскольку напрямую влияет на
  производительность, энергопотребление
  и отзывчивость систем. Улучшения в этой области позволяют
  оптимизировать использование ресурсов
  в современных вычислительных платформах.
\end{quote}

\chapter{Фреймворк sched\_ext}
\section{Введение}
\begin{quote}
  Инфраструктура \bf sched\_ext \normalfont предоставляет возможности
  для разработки и исполнения планировщиков процессов на базе набора
  eBPF программ исполняемых в
  виртуальной машине ядра Linux.

  sched\_ext позволет динамически подключать альтернативные алгоритмы
  планирования без
  необходимости модификации и перекомпиляции ядра.

  Более того, даже перезагружать систему нет необходимости, поскольку
  для загрузки
  нового алгоритма sched\_ext просто делает системный вызов bpf(),
  далее как и любая eBPF программа
  алгоритм планирования пройдет верификацию, JIT компиляцию и сразу начнет
  работу в виртуальной машине.

  Инфраструктура sched\_ext встроена в существующую подсистему
  планирования Linux и использует
  стандартные структуры задач (struct task) и очереди runqueue.

  При активации sched\_ext управление выбором следующей задачи происходит из
  общей (для ядер процессора) очереди dsq (dispatch queue) задачи в которую
  помещает алгоритм планирования. При этом предоставляется
  возможность модификации
  алгоритма перехода задач из общей очереди в локальные dsq (локальные очереди
  исполнения dsq -- очереди задач для каждого отдельного ядра процессора).
\end{quote}

\section{Целостность}
\begin{quote}
  Ядро Linux сохраняет контроль над важными аспектами выполнения, включая:
  \begin{itemize}
    \item переключение контекста
    \item управление состояниями задач
    \item обработку прерываний и таймеров
    \item обеспечение изоляции
  \end{itemize}

  Благодаря этому sched\_ext реализует модель управляемого расширения, в которой
  пользовательский (динамически подгружаемый) код не может напрямую
  нарушить целостность ядра.
\end{quote}

\section{Архитектура}
\begin{quote}
  На sched\_ext распостраняются архитектурные особенности eBPF,\\
  (sched\_ext реализован через eBPF, sched\_ext планировщик является eBPF
  программой).

  eBPF байт-код (скомпилированная eBPF программа) всегда проходит верификацию
  перед тем как он будет отправлен в виртуальную машину или в JIT компилятор
  (предоставляется возможность не использовать JIT компилятор вовсе,
    скомпилированный байт-код после верификации сразу будет исполняться в
  виртуальной машине).

  Верификация предполагает такие шаги как:
  \begin{itemize}
    \item проверка на завершимость

      (проверяется что во всех возможных путях
        графа потока управления (CFG, control flow graph) программа
        завершается и не останется в\\ неопределенном состоянии,
      бесконечном цикле)

    \item запрет небезопасных операций с памятью

      (доступ к динамической памяти предоставляется
        через вспомогательные функции которые работают с памятью
        владение которой
      заранее определены за этой eBPF программой (механизм eBPF Maps)).
  \end{itemize}

  Эти свойства обеспечивают предсказуемость и стабильность работы реализованного
  через sched\_ext планировщика, при этом даже если какие-то ошибки с
  eBPF программой
  все таки будут обнаружены во время исполнения произойдет откат
  (fallback) на стандартный
  планировщик EEVDF.

  Основные функции программного интерфейса sched\_ext:
  \begin{itemize}
    \item select\_cpu() -- выбор потока исполнения (физического или
      логического ядра) процессора
    \item enqueue() -- вставка задачи в глобальную очередь dsq
    \item dispatch() -- перемещение задачи в локальную dsq
  \end{itemize}

  Очистка очередей (постановка задач на исполнение из очередей) происходит
  автоматически. Каждый тик системного таймера $ 1/HZ $ проверяется возможность
  исполнять задачу дальше ($ HZ $ -- частота системного таймера).
  Исполняемая задача
  может быть приостановлена прерыванием сколь угодно раз.

  Задача снимается с выполнения из-за обнуления ее scx\_slice, это происходит
  автоматически когда заканчивается выделенная задаче квота, также есть
  возможность в алгоритме планирования обнулить (специальным прерыванием) задаче
  scx\_slice (таким образом получаем вытеснение планировщиком).

  Как только переменная scx\_slice обнулена ядро считается доступным
  и происходит выбор
  следующей задачи из dsq.
\end{quote}

\chapter{Обзор литературы}
Данная глава представляет собой обзор новых довольно интересных статей
опубликованных со времени написания [2].

\section{Linux Kernel Scheduler Evaluation for Performance-Critical Telecom
Workloads}
\begin{quote}
  В работе рассматривается широкое внедрение облачных технологий
  в телекоммуникационном секторе (telco), что требует систем,
  способных обеспечивать низкие задержки.
  Основной проблемой, с которой сталкивается Ericsson в облачных
  средах на базе Kubernetes, является возникновение
  высоких задержек, когда загрузка процессора превышает 50\%. Это делает оценку
  производительности планировщика LAVD в диапазоне нагрузок от 50\% до 95\%
  необходимой практически (на практике) задачей, чтобы обеспечить
  функционирование
  telco-приложений в соответствии с их назначением.

  Центральной целью диссертации является оценка эффективности планировщика
  Latency-criticality Aware Virtual Deadline (LAVD) при обработке критичных к
  производительности телекоммуникационных рабочих нагрузок. LAVD,
  первоначально разработанный
  для игровых рабочих нагрузок, которые имеют сходство
  с telco-нагрузками по требованиям к задержке и ресурсам, представляет собой
  перспективную попытку решения проблем с задержками. Планировщик
  LAVD был реализован с использованием
  новой инфраструктуры sched\_ext в ядре Linux.

  Для проведения оценки был разработан специальный симулятор. Этот
  настраиваемый, многопоточный симулятор,
  написанный на C++, генерирует синтетические рабочие нагрузки,
  имитирующие характеристики трафика telco-систем,
  основанные на статистическом анализе данных трассировки Ericsson.
  Для моделирования времени выполнения (burst times)
  реальных рабочих нагрузок трафика использовался статистический
  анализ, который показал, что распределение лучше всего
  описывается бета-распределением, что дало наибольшее значение p-value (0.084)
  при проверке критерием\\ Колмогорова-Смирнова. Симулятор также
  поддерживает генерацию фоновых интерферирующих
  рабочих нагрузок, которые конкурируют за время ЦП, позволяя
  моделировать реалистичные сценарии конфликта.

  В ходе исследования сравнивались три планировщика: LAVD,
  scx\_simple (еще один планировщик sched\_ext)
  и EEVDF, который является стандартным планировщиком ядра
  Linux и служил базовой единицей для сравнения (baseline) производительности.
  EEVDF подробно описан в [2]. LAVD, как планировщик, ориентированный
  на критичность
  задержки, использует сложную модель, основанную на времени выполнения, частоте
  пробуждения и частоте ожидания, чтобы назначать более ранние виртуальные
  дедлайны (Virtual Deadlines) более критичным задачам. В отличие от них,
  scx\_simple -- это минималистичный планировщик, который по
  умолчанию использует взвешенное виртуальное время,
  но не поддерживает перехват (preemption), что отличает его от EEVDF и LAVD.

  Результаты показали, что LAVD имеет потенциал для значительного
  сокращения среднего времени
  оборота (mean turnaround time), особенно в сценариях с высокой
  загрузкой процессора и наличием интерферирующих
  рабочих нагрузок. В среде Kubernetes Minikube LAVD
  продемонстрировал улучшение среднего времени оборота по сравнению
  с EEVDF в диапазоне от 6\% до 81\%, а улучшение 99-го перцентиля (tail
  latency) достигало 90\%. Однако, scx\_simple показал удивительно
  хорошие результаты, превзойдя LAVD,
  когда количество интерферирующих рабочих нагрузок было низким.
  Например, в условиях, типичных для Ericsson
  (50\% загрузки ЦП трафиком и 10\% интерферирующей нагрузкой),
  scx\_simple постоянно превосходил LAVD.

  Ключевой вывод исследования состоит в том, что превосходство не принадлежит
  какому-то одному конкретному планировщику, а скорее демонстрируется
  потенциалом
  всей инфраструктуры sched\_ext. Эта гибкость, позволяющая быстро
  проводить эксперименты и оптимизировать код,
  делает ее перспективным инструментом для адаптации планирования ЦП
  к требованиям, специфичным для домена telco.
  Кроме того, попытки оптимизировать параметры LAVD, такие как
  минимальный и максимальный временной срез, не привели к
  значительным улучшениям по сравнению с настройками по умолчанию,
  что позволяет предположить, что LAVD уже хорошо
  оптимизирован для широкого спектра сценариев.

  Среди направлений для будущей работы предлагается улучшение
  симулятора за счет использования более широкого
  и разнообразного набора трасс или непосредственного использования
  трасс для управления выполнением вместо статистических
  распределений. Также рекомендуется расширить анализ, включив
  дополнительные метрики, такие как время ожидания
  и количество переключений контекста, а также провести оценку
  планировщиков в распределенном кластере Kubernetes,
  чтобы выявить потенциальные узкие места, которые могут не
  проявляться в локальной среде Minikube.
\end{quote}

\section{Rethinking Provenance Completeness with
a Learning-Based Linux Scheduler}
\begin{quote}
  Проблема обеспечения полноты данных о происхождении (provenance)
  критически важна для трассируемости действий системы,
  что необходимо для анализа первопричин угроз безопасности и их
  последствий. Системы сбора данных о происхождении должны
  функционировать как эталонный монитор (reference monitor),
  гарантируя полный захват всех системных событий, чтобы
  ведение журнала нельзя было обойти. Однако, современные системы
  сбора данных сталкиваются с серьезной проблемой,
  известной как «угроза суперпродюсера» (super producer threat), при
  которой чрезмерная генерация событий может перегрузить
  систему, вынуждая ее отбрасывать критически важные для безопасности
  записи, что позволяет злоумышленнику скрыть свои
  действия. Эта угроза представляет значительный вызов гарантиям
  безопасности эталонного монитора.

  Существующие решения и подходы сталкиваются с серьезными
  ограничениями при противодействии угрозе суперпродюсера. Традиционные
  планировщики Linux, такие как CFS и EEVDF, разработаны для
  достижения общих целей производительности, таких как
  пропускная способность, справедливость и задержка, но им не хватает
  понимания уникальных требований полноты данных
  о происхождении. Эта нехватка приводит к потере данных, что
  компрометирует надежность и безопасность системы.
  Некоторые современные защитные механизмы, например NoDrop,
  предлагают изоляцию ресурсов, но их внедрение затруднительно,
  поскольку требует специализированной аппаратной поддержки
  (например, Intel Memory Protection Keys), тесно связано с
  устаревшими ядрами и может вызывать ошибки, связанные с атомарными
  операциями, потенциально приводящие
  к сбоям ядра (kernel panics).

  В качестве инновационного решения этих проблем представлена система
  Aegis -- самообучающийся планировщик для
  ядра Linux, специально разработанный для обеспечения полноты данных
  о происхождении. Основная идея заключается в том,
  что планировщик ядра может решить проблему несвоевременного
  потребления генерируемых событий, которое приводит к переполнению
  буфера и потере данных, путем выделения достаточных ресурсов
  системе происхождения. Разработка Aegis преследует три основные
  цели: полнота (захват всех событий даже при экстремальных
  нагрузках), эффективность (поддержание или улучшение производительности
  системы) и справедливость (сбалансированное распределение ресурсов
  для предотвращения "голодания" задач).

  Архитектура Aegis основана на двухслойном подходе, где первый слой
  создает основу планирования, а второй слой
  настраивает ее с помощью обучения для оптимизации
  производительности и смягчения атак. Планировщик использует основанную
  на очередях (queue-based) структуру, где задачи делятся на основную
  и несколько непервичных очередей. Непервичные очереди,
  предназначенные для задач, связанных с происхождением, имеют
  заданное время ожидания, которое выступает в качестве естественного
  бюджета ресурсов. Очередь становится доступной для обработки только
  тогда, когда время, прошедшее с момента последнего
  выполнения задачи в ней, превышает установленное время ожидания,
  что обеспечивает строгую политику выделения ресурсов
  и предотвращает перегрузку. Aegis также обеспечивает
  справедливость, потребляя наиболее «голодные» непервичные
  очереди (те, которые ждали дольше всего), гарантируя
  пропорциональное распределение ресурсов и предотвращая "голодание"
  задач.

  Ключевым элементом Aegis является использование обучения с
  подкреплением (Reinforcement Learning, RL),
  реализуемого с помощью легковесной DeepQ-Network (DQN). DQN
  прогнозирует оптимальные решения о планировании, основываясь
  на контексте задачи, который включает как поведенческие
  характеристики задачи, так и признаки состояния системы
  происхождения (например, скорость генерации событий, доступность буфера).

  Процесс обучения управляется двойным механизмом вознаграждения:
  вознаграждение за происхождение ($r_c$) наказывает за потерю событий
  для обеспечения полноты, а вознаграждение за утилизацию ($r_p$)
  минимизирует простой ЦП для повышения общей эффективности.
  Aegis реализован в пространстве ядра Linux с использованием подсистемы
  eBPF и фреймворка sched\_ext.

  В результате оценки Aegis с использованием различных
  макробенчмарков и двух систем происхождения (Sysdig и eAudit)
  была подтверждена его эффективность. Aegis последовательно
  демонстрировал нулевую потерю событий во всех тестовых сценариях,
  даже в условиях высоких нагрузок, где другие планировщики, такие как
  EEVDF, LAVD и Rusty, теряли от 39\% до более 98\% событий. Более
  того, Aegis не только предотвращает потерю событий,
  но и обеспечивает высокую производительность, в среднем улучшая
  время выполнения по сравнению с EEVDF, LAVD и Rusty.
  Общие вычислительные затраты, связанные с планированием (включая
  вывод нейронной сети), остаются низкими: в типичных сценариях
  они составляют менее 0.5\%, а в самых требовательных -- около
  2.44\%, благодаря использованию дельта-функции для пропуска
  ненужных решений планирования.

  Таким образом, Aegis обеспечивает выполнение гарантий безопасности
  эталонного монитора для систем сбора данных
  о происхождении, эффективно предотвращая угрозу суперпродюсера
  путем интеграции обучения с подкреплением в планировщик ядра.
  Aegis доказывает, что адаптивный, управляемый данными подход
  является мощным и производительным способом устранения
  критических проблем, с которыми не справляются традиционные и
  аппаратные механизмы защиты.
\end{quote}

\section[Mixture-of-Schedulers]{Mixture-of-Schedulers: An Adaptive Scheduling
Agent as a Learned Router for Expert Policies}
\begin{quote}
  Современные планировщики операционных систем сталкиваются с
  серьезной проблемой: единая, статичная политика
  не может обеспечить оптимальную производительность в условиях
  разнообразия и динамичности нагрузок, характерных
  для современных систем. Рост гетерогенного оборудования (например,
  P/E-ядер) и разнообразных архитектур
  приложений (микросервисы, интерактивные задачи, пакетная обработка)
  обострил фундаментальные компромиссы между
  справедливостью, пропускной способностью и задержкой. В ответ на
  эту проблему, статья предлагает новую парадигму:
  динамический выбор оптимальной политики из портфеля
  специализированных планировщиков вместо проектирования единого,
  монолитного решения.

  Эта философия реализована в виде Адаптивного Агента Планирования
  (Adaptive Scheduling Agent, ASA),
  который представляет собой легковесную структуру, выступающую в
  роли интеллектуального маршрутизатора для "экспертных"
  политик планирования. ASA разработан на основе расширяемого интерфейса
  планировщика Linux, sched\_ext. Архитектура ASA декомпозирует
  сложную задачу планирования на две более управляемые
  подзадачи: распознавание шаблона рабочей нагрузки и сопоставление
  политики. Это позволяет ASA интеллектуально
  подбирать наиболее подходящую политику из своего портфеля экспертов
  во время выполнения.

  В основе интеллекта ASA лежит цикл восприятия, решения и действия.
  Модуль Восприятия (Perception module) непрерывно
  отслеживает метрики времени выполнения, такие как использование
  CPU, активность I/O и сетевой трафик, собирая данные
  из различных источников, включая программы eBPF и файловую систему
  procfs. Модуль Решения (Decision module) использует обученную
  модель машинного обучения (классификатор на основе ансамбля,
  преимущественно XGBoost) для распознавания текущего шаблона нагрузки.
  Для обеспечения стабильности решений в динамической среде
  применяется алгоритм Взвешенного по Времени Вероятностного Голосования
  (Time-Weighted Probability Voting), который использует механизм
  голосования с экспоненциальным затуханием для фильтрации
  кратковременного системного шума. Модуль Действия (Action module)
  затем выполняет динамическое переключение на
  выбранный оптимальный планировщик через фреймворк sched\_ext.

  Развертывание ASA включает комплексный трехэтапный автономный
  процесс подготовки (Offline Prepare Pipeline),
  который систематически создает надежного агента планирования. Он
  начинается с Прототипного Обучения (Prototype Learning)
  для создания базовой модели распознавания и первичного
  сопоставления планировщиков, за которым следует Динамическая Калибровка
  Накладных Расходов (Dynamic Overhead Calibration), имитирующая
  стоимость переключения планировщиков. Завершающий этап, Обучение
  Модели Обобщения (Generalization Model Training), позволяет ASA
  уточнить свои модели в реальной среде. Для оценки эффективности авторы
  разработали Критерий Оценки, Ориентированный на Пользовательский
  Опыт (User Experience Oriented Evaluation Criteria), который измеряет
  производительность на основе метрик, напрямую влияющих на
  восприятие пользователя (например, задержка взаимодействия и плавность UI),
  смещая цель оптимизации от системной эффективности к оптимизации
  пользовательского опыта. Этот критерий отражает нелинейную природу
  человеческого восприятия, выделяя "Зону Наилучшего Восприятия"
  ("Sweet Spot Region").

  Комплексная оценка подтвердила, что парадигма динамического выбора
  ASA превосходит статическую оптимизацию.
  ASA стабильно превосходит стандартный планировщик Linux (EEVDF), показывая
  лучшие результаты в 86.4\% тестовых сценариев. Выбранные ASA
  политики являются близкими к оптимальным, входя в тройку
  лучших планировщиков в 78.9\% всех сценариев. В некоторых сценариях
  со смешанными нагрузками ASA даже превосходит
  "Статический Оракул", динамически переключая политики внутри задачи
  для отслеживания мгновенного оптимума.

  Агент также продемонстрировал сильную способность к обобщению,
  поддерживая или даже улучшая производительность
  на новых, ранее невиденных аппаратных платформах.

  Практичность ASA подтверждается минимальными накладными расходами: агент
  потребляет в среднем всего 1.45\% одного ядра CPU и 297 МБ памяти.
  Хотя потолок производительности ASA определяется качеством
  и разнообразием портфеля экспертных планировщиков, это также
  является преимуществом, поскольку позволяет масштабировать
  улучшения путем интеграции новых, более продвинутых планировщиков,
  разработанных сообществом. В целом, Адаптивный Агент Планирования
  предлагает жизнеспособный технический путь для создания следующего
  поколения интеллектуальных, адаптивных планировщиков операционных систем.
\end{quote}

\chapter{Реализация алгоритма EEVDF через фреймворк sched\_ext}
\section{Задачи}
\begin{quote}
  \begin{itemize}
    \item Исследовать диссертацию [7]
    \item Реализовать в соответствии с описанным алгоритмом планировщик
      EEVDF используя sched\_ext
    \item Провести сравнение задержки между алгоритмами
  \end{itemize}
\end{quote}

\section{Мотивация}
\begin{quote}
  Выбор данной задачи обусловлен несколькими факторами и открывает
  важные направления для дальнейших исследований.

  Реализация планировщика EEVDF в рамках инфраструктуры sched\_ext
  создает возможность
  провести количественную оценку косвенных затрат,
  возникающих при использовании данной конфигурации, что необходимо
  для абсолютной
  оценки эффективности получившегося практического решения.

  Кроме того, разработанная реализация служит воспроизводимой основой
  для будущего
  прямого сравнения альтернативной реализации планировщика (специально
  разработанного для гетерогенного процессора) и позволяет выявлять
  практические ограничения.

  Наконец, работа приносит автору существенный практический опыт
  разработки и интеграции
  планировщиков в системное окружение, что важно для последующих
  экспериментальных и прикладных исследований.
\end{quote}

\section{Краткое погружение в реализацию}
\begin{quote}
  В основе алгоритма EEVDF лежит присвоение каждой задаче
  виртуального допустимого времени
  (VE) и виртуального крайнего срока (VD), вычисляемых следующим образом:

  VE = max(VE\_previous, V\_now - slice), где V\_now -- глобальное
  виртуальное время, а slice -- временая квота задачи 
  (упомянутый ранее scx\_slice).

  VD = VE + (slice / weight, масштабируется таким образом, чтобы
  задачи с более высоким весом (более высоким приоритетом) получали
  более короткие эффективные сроки.

  Задачи распределяются на основе самого раннего VD, что способствует
  справедливости: более ресурсоемкие задачи потребляют больше
  виртуального времени, но соответственно наказываются. Это
  предотвращает бесконечную задержку задач с низким приоритетом, что
  является распространенной проблемой в других алгоритмах
  справедливого распределения.
  
  В моей реализации я поддерживаю глобальный контекст (eevdf\_ctx),
  отслеживающий vtime\_now (текущее виртуальное время) и total\_weight (сумма
  весов всех задач). Общая очередь диспетчеризации dsq хранит задачи,
  упорядоченные по их виртуальному времени VD, используя встроенную
  в sched\_ext функцию вставки с упорядочением по виртуальному времени
  (scx\_bpf\_dsq\_insert\_vtime()).
\end{quote}

\section{Подробности реализации}
\begin{quote}
  Инициализация и глобальное состояние:
  Мы начинаем с определения карты BPF для глобальных данных (global\_data) для
  хранения контекста EEVDF. Карта статистики для каждого ЦП отслеживает такие
  метрики, как выбор незадействованных ЦП и добавление задач в очередь для
  отладки. Общая DSQ (ID 0) создается во время инициализации
  (eevdf\_init), обеспечивая единую упорядоченную очередь для всех задач.
  Выбор ЦП (eevdf\_select\_cpu):
  Когда задача просыпается, мы используем выбор ЦП по умолчанию из
  sched\_ext, но проверяем наличие незадействованных ядер. Если
  обнаруживается свободный процессор, мы увеличиваем статистику и
  добавляем задачу в локальную очередь задач (DSQ) с использованием
  среза по умолчанию — оптимизируя выполнение для немедленного
  запуска и уменьшая накладные расходы на миграцию.
  Постановка задач в очередь (eevdf\_enqueue):
  Здесь происходит волшебство EEVDF. Мы получаем глобальный контекст,
  ограничиваем
  виртуальное допустимое время (VE) задачи, чтобы предотвратить отрицательные
  задержки, и вычисляем виртуальный крайний срок (VD) как VE + (срез * SCALE /
  вес). Задача добавляется в общую очередь задач (DSQ) с
  использованием семантики,
  упорядоченной по виртуальному времени
  (scx\_bpf\_dsq\_insert\_vtime), обеспечивая порядок «сначала самый
  ранний крайний срок». Коэффициент SCALE (100) обеспечивает точность
  с фиксированной запятой для дробных вычислений.

  Диспетчеризация задач (eevdf\_dispatch):
  Здесь царит простота: мы перемещаем задачи из общей очереди DSQ в
  локальную очередь на текущем ЦП, позволяя ядру выбирать следующую
  готовую к выполнению задачу на основе предварительно упорядоченного
  виртуального времени (VD).
  Хуки жизненного цикла задачи:
  Начало выполнения (eevdf\_running): продвижение глобального
  виртуального времени, если виртуальное время задачи превышает его,
  обеспечивая монотонный прогресс.
  Остановка (eevdf\_stopping): обновление виртуального времени задачи
  путем добавления потребленного времени, масштабированного по весу,
  с учетом фактического времени выполнения.
  Включение/отключение (eevdf\_enable/eevdf\_disable): корректировка
  total\_weight при входе или выходе задач из планировщика,
  поддерживая точное глобальное состояние.
  Изменение веса (eevdf\_set\_weight): динамическая корректировка
  виртуального времени для сохранения задержки (разницы между
  глобальным виртуальным временем и виртуальным временем задачи) при
  изменениях веса. Это включает пропорциональное масштабирование во
  избежание несправедливых скачков приоритета.

  Код избегает сложных структур данных, полагаясь на примитивы DSQ из
  sched\_ext для повышения эффективности. Обработка ошибок
  минимальна, с ранним возвратом при сбоях поиска в карте, что
  обеспечивает приоритет надежности в контексте ядра.
  Тестирование и проверка
  На практике этот планировщик «просто работает» — задачам
  справедливо выделяется процессорное время пропорционально их весам,
  с гарантией низкой задержки для интерактивных рабочих нагрузок.
  Счетчики статистики показывают эффективное использование процессора
  в режиме ожидания и закономерности постановки задач в очередь.
  Например, при смешанных нагрузках (например, задачи, интенсивно
    использующие процессор, и задачи, интенсивно использующие
  ввод-вывод) EEVDF превосходит CFS по показателям задержки в конце
  очереди, поскольку виртуальные крайние сроки предотвращают
  чрезмерное использование ресурсов.

  Будущие улучшения и соображения
  Хотя этот прототип отражает суть EEVDF, существует множество возможностей для
  его усовершенствования: виртуальное время для каждого ЦП с учетом
  NUMA-архитектуры, адаптивное разделение на сегменты для переменных рабочих
  нагрузок или интеграция с энергоэффективным планированием. Гибкость
  sched\_ext делает эти расширения простыми.
  В заключение, реализация EEVDF через sched\_ext демонстрирует
  возможности BPF в расширяемости ядра — превращая теоретические
  алгоритмы в развертываемые решения с минимальными накладными
  расходами. Эта работа не только решает исходную задачу, но и
  открывает двери для вклада сообщества, потенциально влияя на
  планирование в Linux. Полный код и инструкции по развертыванию см.
  в репозитории [ссылка, если доступна]. Если вы экспериментируете с
  пользовательскими планировщиками, EEVDF предлагает привлекательную
  отправную точку — справедливую, эффективную и элегантно простую.
\end{quote}

\section{Итоги}
\begin{quote}
\end{quote}

%\chapter{Матмодель задачи}

%\chapter{Дальнейшие планы}

\chapter*{Заключение}
\begin{quote}
  \quad В данной работе были рассмотрены продвинутые алгортмы планирования.
  Были описаны наиболее актуальные решения, используемые для задач планирования
  в современных операционных системах, такие как CFS/EEVDF и sched\_ext.
  Продолжающееся развитие данной области показывает, что решаемые проблемы
  актуальны и востребованны.

  \quad В работе преднамеренно было опущено обсуждение важности разработки
  более эффективных планировщиков в тех местах, где это допустимо в рамках
  формата отчета о научно-исследовательской работе. Это сделано по следующим
  причинам: во-первых, с момента публикации [1] не произошло качественно новых
  изменений в оценке значимости рассматриваемой темы -- она остаётся
  исключительно
  актуальной, и повторение ранее изложенного не представляется целесообразным;
  во-вторых, данную работу лучше всего рассматривать как логичное
  продолжение ранее
  проведённого исследования, поэтому внимание к важности целесообразно уделить
  именно в заключении.

  \quad Разработка более эффективных алгоритмов планирования имеет ключевое
  значение в условиях постоянно растущих требований к производительности
  вычислительных систем. Современные задачи, такие как обеспечение предсказуемой
  задержки, адаптация к разнородным нагрузкам, энергоэффективность, а
  также гетерогенное устройство наиболее современных вычислительных машин
  требуют всё более точных и адаптивных решений. Поэтому исследования в этой
  области способствуют не только улучшению существующих реализаций,
  но и открывают путь к созданию новых, более универсальных и
  надёжных планировщиков.

  \quad Таким образом, проведённое исследование дополняет и расширяет
  картину, описанную в [1]. Оно укрепляет базу, необходимую для перехода
  на прикладной уровень: разработки более эффективных алгоритмов и создания
  программных решений, лучше соответствующих специфике решаемых задач.
  В будущем планируется сосредоточиться на подготовке образа тестовой системы
  с ядром Linux и написании пакета для сбора метрик качества обработки задач
  планирования.
  В дальнейшем работа в рамках этой темы может пойти в различных направлениях:
  от внесения инкрементальных патчей в CFS/EEVDF на основе показаний тест-пакета
  до создания специализированных sched\_ext планировщиков,
  построенных на продвинутых
  алгоритмах для разнообразных прикладных задач
\end{quote}

\renewcommand{\bibname}{\large СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ}
\begin{thebibliography}{9}
  \vspace*{0.3cm}
  \bibitem{1}
  Павел Е. Шаго Отчет о научно-исследовательской работе: Планировщики б. и. 2024
  \bibitem{2}
  Павел Е. Шаго Отчет о научно-исследовательской работе: Планировщики 2 б. и.
  2025
  \bibitem{3}
  Joseph Y-T. Leung\ Handbook of Scheduling: Algorithms, Models, and
  Performance Analysis CRC Press 2004
  \bibitem{4} Michelle Galin, Anna Hedblom Linux Kernel Scheduler Evaluation
  for Performance-Critical Telecom Workloads Linköping University 2025
  \bibitem{5} Jinsong Mao, Benjamin E. Ujcich, Shiqing Ma Rethinking Provenance
  Completeness with a Learning-Based Linux Scheduler arXiv 2025
  \bibitem{6} Xinbo Wang, Shian Jia, Ziyang Huang, Jing Cao, Mingli Song
  Mixture-of-Schedulers: An Adaptive Scheduling Agent as a Learned Router for
  Expert Policies arXiv 2025
  \bibitem{7}
  Ion Stoica, Hussein Abdel-Wahab Earliest Eligible Virtual Deadline First
  : A Flexible and Accurate Mechanism for Proportional Share Resource Allocation
  Old Dominion University 1996

  \iffalse
  \bibitem{4} Tang Qinan, Gao Xing, Li Guilin, Lin Juncong Optimizing Linux
  scheduling based on global runqueue with SCX IEEE International
  Conference SMC 2024

  \bibitem{6}
  Jiacheng Xu, Dylan Wolff, Han Xing Yi, Jialin Li, Abhik Roychoudhury
  Concurrency Testing in the Linux Kernel via eBPF arXiv 2025
  \bibitem{7}
  Andrew S. Tanenbaum, Herbert Bos\ MODERN OPERATING SYSTEMS Pearson
  Education 2023
  \bibitem{8}
  Zhong, Shawn Wanxiang, Jing Liu, Andrea Arpaci-Dusseau, Remzi Arpaci-Dusseau
  Revealing the Unstable Foundations of eBPF-Based Kernel Extensions Twentieth
  European Conference on Computer Systems 2025
  \bibitem{9}
  Liz Rice Learning eBPF O’Reilly Media, Inc 2023
  \bibitem{11}
  Michael J. Morrison\ Resource Management and Scheduling
  in Multitasking Operating Systems CRC Press 2017
  \bibitem{12}
  Daniel Hodges Scheduling at Scale : eBPF Schedulers with
  Sched\_ext USENIX Association 2024
  \bibitem{13}
  Mores Konstantinos User-space guided memory management with eBPF
  NTUA 2025
  \bibitem{14}
  Xiaobo Zheng, Zihao Duan, Shiyi Li, Haojun Hu, Wen Xia
  F4: Fast, Flexible and stable-Fortified User-Space Thread Scheduling Framework
  International Conference on Networking, Architecture and Storage IEEE 2024
  \bibitem{15}
  Saito Shogo, Kei Fujimoto Port contention aware task scheduling for
  SIMD applications
  IEEE Access 2024
  \bibitem{16}
  Feitong Qiao, Yiming Fang, Asaf Cidon Energy-Aware Process Scheduling in Linux
  ACM SIGENERGY Energy Informatics 2024
  \bibitem{17}
  Torvalds L. Linux Kernel [Электронный ресурс] / L. Torvalds.
  -- Режим доступа: \url{https://github.com/torvalds/linux} -- Дата обращения
  15.04.2025.
  \bibitem{18}
  sched-ext/scx [Электронный ресурс]. -- Режим доступа: \\
  \url{https://github.com/sched-ext/scx} -- Дата обращения 27.04.2025.
  \bibitem{19}
  lkml [Электронный ресурс]. -- Режим доступа: \url{https://lkml.org}
  -- Дата обращения 20.04.2025.
  %\bibitem{20}
  %eBPF for windows [Электронный ресурс]. -- Режим доступа:
  %\url{https://github.com/microsoft/ebpf-for-windows}
  %-- Дата обращения 01.05.2025.
  \bibitem{20}
  lwn article 925371 [Электронный ресурс]. -- Режим доступа:
  \url{https://lwn.net/Articles/925371}
  -- Дата обращения 06.05.2025.
  \bibitem{21}
  Sungju Huh, Jonghun Yoo, Seongsoo Hong Analytical Evaluation of Linux
  CFS Scheduler under Extreme Workload ITC-CSCC 2011
  %\bibitem{20}
  %S. A. Cook The complexity of theorem-proving procedures, in Procedings of the
  %3rd Annual ACM Symposium on Theory of Computing, Association for Computing
  %Machinery 1971
  %\bibitem{21}
  %M. R. Garey and D. S. Johnson, Computers and Intractability: A Guide to the
  %Theory of NP-Completeness W. H. Freeman 1979
  %\bibitem{22}
  %R. M. Karp, Reducibility among combinatorial problems, in R. E. Miller and
  %J. W. Thatcher (eds), Complexity of Computer Computations Plenum Press 1972
  \fi
\end{thebibliography}

\end{document}
